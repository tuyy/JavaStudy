{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 붓꽃 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 예제 테스트 세트 정확도: 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "iris_dataset = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        iris_dataset['data'], iris_dataset['target'], random_state=0) # 훈련 데이터와 테스트 데이터 분리\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1) # 알고리즘 선택\n",
    "knn.fit(X_train, y_train) # 훈련..\n",
    "\n",
    "\n",
    "print(\"붓꽃 예제 테스트 세트 정확도: {:.2f}\".format(knn.score(X_test, y_test))) # 평가.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 타이타닉 toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass      int64\n",
       "Sex         int64\n",
       "SibSp       int64\n",
       "Parch       int64\n",
       "Ticket      int64\n",
       "Cabin       int64\n",
       "Embarked    int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# 1. csv에서 train, test set 가져오기\n",
    "train = pd.read_csv('/Users/tuyy/Desktop/all/train.csv')\n",
    "test = pd.read_csv('/Users/tuyy/Desktop/all/test.csv')\n",
    "y_test = pd.read_csv('/Users/tuyy/Desktop/all/gender_submission.csv')\n",
    "\n",
    "# 2. 데이터 전처리\n",
    "def setting_titanic(df, has_Survived=True):\n",
    "    df['Ticket'] = df['Ticket'].apply(len)\n",
    "    df['Cabin'] = df['Cabin'].apply(lambda x: 0 if type(x) == float else 1)\n",
    "    df['Embarked'] = df['Embarked'].apply(lambda x: 0 if x == 'C' else (1 if x == 'Q' else 2))\n",
    "    df['Sex'] = df['Sex'].apply(lambda x: 0 if x == 'male' else 1)\n",
    "    #df['Name'] = df['Name'].apply(len) # nan 처리해야함\n",
    "    #df['Fare'] = df['Fare'].apply(int) # nan 처리해야함\n",
    "    #df['Age'] = df['Age'].astype(int) # nan 처리해야함\n",
    "    if has_Survived:\n",
    "        y_df = df['Survived'].values\n",
    "        df.drop(['Survived', 'PassengerId', 'Name', 'Age', 'Fare'], axis=1,inplace=True)\n",
    "        return df, y_df\n",
    "    else:\n",
    "        df.drop(['PassengerId', 'Name', 'Age', 'Fare'], axis=1,inplace=True)\n",
    "        return df\n",
    "    \n",
    "X_train, y_train = setting_titanic(train, has_Survived=True)\n",
    "\n",
    "X_test = setting_titanic(test, has_Survived=False)\n",
    "y_test = y_test['Survived'].values\n",
    "\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model명: KNN\n",
      "train 세트 정확도: 0.81\n",
      "test 세트 정확도: 0.76\n",
      "==========================\n",
      "Model명: 로지스틱회귀\n",
      "train 세트 정확도: 0.80\n",
      "test 세트 정확도: 0.94\n",
      "==========================\n",
      "Model명: 서포트벡터머신\n",
      "train 세트 정확도: 0.80\n",
      "test 세트 정확도: 0.97\n",
      "==========================\n",
      "Model명: 결정트리\n",
      "train 세트 정확도: 0.82\n",
      "test 세트 정확도: 0.85\n",
      "==========================\n",
      "Model명: 랜덤포레스트\n",
      "train 세트 정확도: 0.87\n",
      "test 세트 정확도: 0.83\n",
      "==========================\n"
     ]
    }
   ],
   "source": [
    "# 3. 모델 적용\n",
    "for model in [('KNN', KNeighborsClassifier(n_neighbors=2)),\n",
    "              ('로지스틱회귀', LogisticRegression(C=1)),\n",
    "              ('서포트벡터머신',LinearSVC()),\n",
    "              ('결정트리', DecisionTreeClassifier(max_depth=4, random_state=0)),\n",
    "              ('랜덤포레스트', RandomForestClassifier(random_state=2018))]:\n",
    "    \n",
    "    algo = model[1].fit(X_train, y_train)\n",
    "\n",
    "    # 4. 결과 확인\n",
    "    print('Model명: ' + model[0])\n",
    "    print(\"train 세트 정확도: {:.2f}\".format(algo.score(X_train, y_train))) # 평가..\n",
    "    print(\"test 세트 정확도: {:.2f}\".format(algo.score(X_test, y_test))) # 평가..\n",
    "    print('==========================')\n",
    "    \n",
    "    # 5. 그래프??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 타이타닉 toy 프로젝트 진행하면서..\n",
    "* 전처리에 대한 고민이 매우 많이 필요할듯..\n",
    "    * Null 데이터(Name, Fare, Age)\n",
    "    * 텍스트 feature -> 원핫인코딩 등등\n",
    "    * 유의미한 특성을 어떻게 뽑아낼까?\n",
    "        * feature 별 중요도 시각화로 유의미한 feature를 넣고 빼고..\n",
    "* 오히려 어떤 model을 쓸지와 model 튜닝작업은 마지막에 해도 될것같음.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
